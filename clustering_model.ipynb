{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGUhj2mqZ30yMrwO6SG4ly",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlskawns/cp2/blob/main/Clustering_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정책 데이터셋 샘플 수 축소를 위한 클러스터링"
      ],
      "metadata": {
        "id": "GaFUfyewuQMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모듈 불러오기"
      ],
      "metadata": {
        "id": "xE7Uk1IXuodh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n",
        "!pip install kmodes"
      ],
      "metadata": {
        "id": "AsxmlG2W-wN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2, l1_l2\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from category_encoders import OrdinalEncoder\n",
        "from kmodes.kprototypes import KPrototypes\n",
        "import copy\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "hMkMv9SKLBPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kGSSbtMlkGr",
        "outputId": "26d1306b-776c-4194-ef84-11a409697750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 불러오기"
      ],
      "metadata": {
        "id": "ob5PP_OAusSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 태깅 추출된 정책 데이터셋 불러오기\n",
        "with open('/content/drive/MyDrive/웰로/data/our_final0117.pkl', 'rb') as f:\n",
        "    data1 = pickle.load(f)\n",
        "# 태깅 추출된 유저 데이터셋 불러오기\n",
        "with open('/content/drive/MyDrive/웰로/data/user_final0117 (1).pkl', 'rb') as f:\n",
        "    user1 = pickle.load(f)\n",
        "# 추천모델A 를 전체 user에 적용해 1차적으로 정책 list sorting (약 39000여개 index list)\n",
        "with open('/content/drive/MyDrive/웰로/data/idx_lst.pkl', 'rb') as f:\n",
        "  idx_lst = pickle.load(f)"
      ],
      "metadata": {
        "id": "-KisGWoWLCq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class policy_clustering():\n",
        "  \"\"\"\n",
        "  정책 데이터셋의 수를 줄이기 위해 군집화를 하는 클래스\n",
        "  정책 데이터 태그를 전처리하고, categorical, numerical data를 군집화 할 수 있는 k-prototypes 클러스터링 진행\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, df, idx_lst):\n",
        "    self.df = df.copy()\n",
        "    self.df = self.df.iloc[idx_lst].reset_index()\n",
        "    \n",
        "    # 필요한 feature만 가져옴\n",
        "    self.df = self.df[['정책ID', '대상연령시작', '대상연령끝', '시도', '중위소득', '관심상황특성', '대상특성', '대상특성상세', 'MB_15', '소관기관유형', '지원유형', '지원유형상세',\n",
        "       '신청절차', '성별', '결혼', '학력', '가구원', '자녀', '자녀상세', '직장', '직장상세']]\n",
        "    \n",
        "    # 취업지원이 두 가지로 나뉘어져 있어 하나로 통합\n",
        "    self.df['MB_15'] = self.df['MB_15'].map(lambda x: x.replace('취업지원', '취업 지원'))\n",
        "\n",
        "    # 이혼&재혼 -> 기혼\n",
        "    self.df['결혼'] = self.df['결혼'].map(lambda x: x.replace('이혼', '기혼').replace('재혼','기혼').replace('기혼,미혼','무관'))\n",
        "\n",
        "    # 기존 샘플 중 직장, 가구원, 결혼에서 무관이 아닌 샘플 추출\n",
        "    sample_1 = list(self.df[(self.df['직장']!='무관')&(self.df['가구원']!='무관')].index.values)\n",
        "    sample_2 = list(self.df[self.df['가구원']!='무관'].index.values)\n",
        "    sample_3 = list(self.df[self.df['결혼']!='무관'].index.values)\n",
        "    self.sample_n = list(set(sample_1 + sample_2 + sample_3))\n",
        "\n",
        "    self.numeric_cols = ['정책ID','대상연령시작','대상연령끝','max_income','min_income'] # 연속형 특성 \n",
        "    self.ordinal_cols = ['시도','소관기관유형','지원유형','성별','결혼','자녀']          # 범주형 특성\n",
        "    self.other_cols = list()  # 전체 원핫으로 바꾼것 포함 범주형 특성\n",
        "  \n",
        "  def class_to_columns(self, df, col):\n",
        "    \"\"\"\n",
        "    feature를 one-hot 인코딩 해주는 함수\n",
        "    중복 태그의 문제를 해결하기 위함\n",
        "    \"\"\"\n",
        "    b = []\n",
        "    for i in df[col]:\n",
        "      if ',' in i:\n",
        "        i = i.split(',')\n",
        "        b.extend(i)\n",
        "      else:\n",
        "        b.append(i) \n",
        "    c = list(set(b))\n",
        "    for i in c:\n",
        "      df[i] = 0\n",
        "    for i in tqdm(range(len(df))):\n",
        "      for j in c:\n",
        "        if j in df[col][i]:\n",
        "          df[j][i] =1\n",
        "\n",
        "    df=df.drop(columns = col)\n",
        "\n",
        "  def class_to_columns_two(self,df, col):\n",
        "    \"\"\"\n",
        "    대상특성, 직장, 지원유형 등의 어느정도 필요하면서 중복이 많은 특성은 클러스터링 시 one hot 인코딩 후 진행할 것.\n",
        "    클러스터링 속성 지정을 위해 함수 재설정\n",
        "    \"\"\"\n",
        "    b = []\n",
        "    for i in df[col]:\n",
        "      if ',' in i:\n",
        "        i = i.split(',')\n",
        "        b.extend(i)\n",
        "      else:\n",
        "        b.append(i) \n",
        "    c = list(set(b))\n",
        "    for i in c:\n",
        "      df[col+i] = 0\n",
        "    for i in tqdm(range(len(df))):\n",
        "      for j in c:\n",
        "        if j in df[col][i]:\n",
        "          df[col+j][i] =1\n",
        "\n",
        "  def income_change(self, df):\n",
        "    \"\"\"\n",
        "    중위소득을 min, max로 나누어 파악할 수 있도록 하는 함수\n",
        "    ex: 0,10,20,30,40 -> min_income = 0, max_income = 40\n",
        "    \"\"\"\n",
        "\n",
        "    df['중위소득'] = df['중위소득'].fillna('')\n",
        "    b = []\n",
        "    df['max_income'] = None\n",
        "    df['min_income'] = None\n",
        "    for i in tqdm(range(len(df['중위소득']))):\n",
        "      if ',' in df['중위소득'][i]:\n",
        "        if '기초생활수급자' in df['중위소득'][i]:\n",
        "          a = df['중위소득'][i].split(',')\n",
        "          a.remove('기초생활수급자')\n",
        "          a = list(set(map(int, a)))\n",
        "          max_income = max(a)\n",
        "          df['max_income'][i] = max_income\n",
        "          df['min_income'][i] = 0\n",
        "        else:\n",
        "          a = df['중위소득'][i].split(',')\n",
        "          a = list(set(map(int, a)))\n",
        "          max_income = max(a)\n",
        "          min_income = min(a)\n",
        "          df['max_income'][i] = max_income\n",
        "          df['min_income'][i] = min_income\n",
        "      elif df['중위소득'][i] =='기초생활수급자':\n",
        "        df['max_income'][i] = 30\n",
        "        df['min_income'][i] = 0\n",
        "      else:\n",
        "        df['max_income'][i] = 200\n",
        "        df['min_income'][i] = 0\n",
        "\n",
        "  def preprocessing_feature(self):\n",
        "    \"\"\"\n",
        "    정책 데이터의 각각의 feature를 User tag와 비교할 수 있도록 전처리하는 함수\n",
        "    중요 tag(MB_15, 대상특성, 직장, 지원유형 등의 태그를 포함)\n",
        "    \"\"\"\n",
        "    print('MB_15 feature 해체 진행 \\n1/5 진행중')\n",
        "    self.class_to_columns(self.df, 'MB_15')\n",
        "    print('중위소득 feature 변경 진행 \\n2/5 진행중')\n",
        "    self.income_change(self.df)\n",
        "    print('대상특성 feature 해체 진행 \\n3/5 진행중')\n",
        "    self.class_to_columns_two(self.df, '대상특성')\n",
        "    print('직장 feature 해체 진행 \\n4/5 진행중')\n",
        "    self.class_to_columns_two(self.df, '직장')\n",
        "    print('지원유형 feature 해체 진행 \\n5/5 진행중')\n",
        "    self.class_to_columns_two(self.df, '지원유형')\n",
        "    self.df = self.df.drop(columns = ['중위소득','대상특성상세','관심상황특성','직장','지원유형상세','신청절차','학력','가구원','자녀상세','직장상세','대상특성','MB_15'])\n",
        "    self.other_cols = list(self.df.drop(columns = self.numeric_cols).columns.values)  # 전체 원핫으로 바꾼것 포함 범주형 특성\n",
        "\n",
        "  def clustering_data(self):\n",
        "    \"\"\"\n",
        "    Ordinal Encoding하여 categorical features를 수치화 한 뒤, 클러스터링을 진행하는 함수\n",
        "    사전에 Elbow Methods를 통해 최적의 군집개수 확인 k=5\n",
        "    \"\"\"\n",
        "    enc = OrdinalEncoder(cols = self.ordinal_cols)\n",
        "    enced_data = enc.fit_transform(self.df)\n",
        "    cat_col_cluster = list(range(0,78))\n",
        "    for i in [1,2,20,21]:\n",
        "      cat_col_cluster.remove(i)\n",
        "    \n",
        "    print('클러스터링 진행')\n",
        "    kproto = KPrototypes(n_clusters=5, max_iter = 3, n_jobs= 4, init='Cao')\n",
        "    kproto.fit_predict(enced_data, categorical=cat_col_cluster)\n",
        "    \n",
        "    self.df['cluster'] = kproto.labels_\n",
        "\n",
        "  def clustered_idx(self):\n",
        "    \"\"\"\n",
        "    군집화 완료된 후, 적절한 군집 내 샘플 500개 및 필요 샘플 500개로 총 1000개의 정책 데이터 샘플을 추출\n",
        "    \"\"\"\n",
        "    data = self.df.drop(self.df.iloc[self.sample_n].index)\n",
        "    data_0 = list(data[data['cluster']==0].sample(100, random_state = 42).index.values)\n",
        "    data_1 = list(data[data['cluster']==1].sample(100, random_state = 42).index.values)\n",
        "    data_2 = list(data[data['cluster']==2].sample(101, random_state = 42).index.values)\n",
        "    data_3 = list(data[data['cluster']==3].sample(100, random_state = 42).index.values)\n",
        "    data_4 = list(data[data['cluster']==4].sample(101, random_state = 42).index.values)\n",
        "\n",
        "    data_lst = data_0+data_1+data_2+data_3+data_4+self.sample_n\n",
        "    return data_lst\n"
      ],
      "metadata": {
        "id": "rMxCu0TI9Wb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class preprocessing_label():\n",
        "  \"\"\"\n",
        "  policy_clustering을 통해 추출한 정책 데이터 샘플 list를 바탕으로\n",
        "  임의의 유저 3000명 대상 조건 부합여부에 따라 labeling(1,0) 하기 위한 클래스\n",
        "  \"\"\"\n",
        "  def __init__(self, user, data, idx_lst, data_lst):\n",
        "    self.user = user.copy()\n",
        "    # 정책 데이터셋 feature engineering\n",
        "    self.loader = policy_clustering(data, idx_lst)\n",
        "    self.data = self.loader.df.iloc[data_lst].reset_index()\n",
        "    print('정책 데이터셋 중위소득 feature 변경 진행 \\n1/3 진행중')\n",
        "    self.loader.income_change(self.data)\n",
        "    self.data['대상특성'] = self.data['대상특성'].map(lambda x: x.replace(' ', ''))\n",
        "    print('정책 데이터셋 대상특성 feature 해체 진행 \\n2/3 진행중')\n",
        "    self.loader.class_to_columns(self.data, '대상특성')\n",
        "    print('정책 데이터셋 MB_15 feature 해체 진행 \\n3/3 진행중')\n",
        "    self.loader.class_to_columns(self.data, 'MB_15')\n",
        "\n",
        "    self.data = self.data.drop(columns = ['중위소득','대상특성상세','관심상황특성','지원유형상세','신청절차','가구원','자녀상세','직장상세','대상특성','MB_15', ''])\n",
        "\n",
        "    self.data = self.data[['정책ID', '대상연령시작', '대상연령끝', '시도', '소관기관유형', '지원유형', '학력', '성별', '결혼','자녀', '직장', 'max_income', 'min_income', \n",
        "                           '질병/부상/질환자', '국가유공자','한부모가정/조손가정',  '다자녀가정',  '해당사항없음', '다문화가족', '북한이탈주민', '농축수산인', '장애인', # '저소득층','독거노인','소년소녀가장','구호구제대상자',\n",
        "                           '개인금융지원', '문화생활 지원', '취업 지원', '창업 지원', '교육지원(8~19세)','의료 지원', '보육지원(0~7세)', '주택-부동산 지원', '성인교육지원', '기업금융지원', '근로자 지원']]\n",
        "    # 유저 데이터셋 feature engineering\n",
        "  def user_preprocessing(self):\n",
        "    # self.user = user.copy()\n",
        "    self.user = self.user.drop(index = self.user[self.user['mb_15'].isnull()].sample(frac=0.9).index.values)\n",
        "    self.user = self.user.drop(index = self.user[self.user['mb_12'].isnull()].sample(frac=0.9).index.values).reset_index()\n",
        "    print('유저 데이터셋 대상특성 feature 해체 진행 \\n1/3 진행중')\n",
        "    self.loader.class_to_columns(self.user, 'mb_10+대상특성')\n",
        "    print('유저 데이터셋 중위소득 feature 변경 진행 \\n2/3 진행중')\n",
        "    self.income_change_user()\n",
        "    print('유저 데이터셋 MB_15 feature 해체 진행 \\n3/3 진행중')\n",
        "    self.user['mb_15'].fillna('관심정책없음',inplace=True)\n",
        "    self.loader.class_to_columns(self.user, 'mb_15')\n",
        "\n",
        "    self.user = self.user.drop(columns = ['시군구','자녀상세','자녀수','자녀','mb_10','mb_11','mb_10+대상특성', 'mb_11+관심상황특성','mb_12','mb_13','mb_14','mb_15','index','저소득층','독거노인','소년소녀가장','구호구제대상자'])\n",
        "    self.user['결혼'] = self.user['결혼'].map(lambda x: x.replace('미혼,기혼','무관'))\n",
        "\n",
        "\n",
        "\n",
        "  def income_change_user(self):\n",
        "    self.user['mb_12'] = self.user['mb_12'].fillna('')\n",
        "    b = []\n",
        "    self.user['max_income'] = None\n",
        "    self.user['min_income'] = None\n",
        "    for i in tqdm(range(len(self.user['mb_12']))):\n",
        "      if '이하' in self.user['mb_12'][i]:\n",
        "        self.user['max_income'][i] = 40\n",
        "        self.user['min_income'][i] = 0\n",
        "      elif '이상' in self.user['mb_12'][i]:\n",
        "        self.user['max_income'][i] = 110     # 100이상은 모두 포함\n",
        "        self.user['min_income'][i] = 100\n",
        "      elif '기초생활수급자' in self.user['mb_12']:\n",
        "        self.user['max_income'][i] = 30\n",
        "        self.user['min_income'][i] = 0\n",
        "      elif '사이' in self.user['mb_12'][i]:\n",
        "        if '40~60' in self.user['mb_12'][i]:\n",
        "          self.user['max_income'][i] = 60\n",
        "          self.user['min_income'][i] = 40\n",
        "        elif '60~80' in self.user['mb_12'][i]:\n",
        "          self.user['max_income'][i] = 80\n",
        "          self.user['min_income'][i] = 60\n",
        "        elif '80~100' in self.user['mb_12'][i]:\n",
        "          self.user['max_income'][i] = 100\n",
        "          self.user['min_income'][i] = 80\n",
        "        else: # 40% 이하\n",
        "          self.user['max_income'][i] = 40\n",
        "          self.user['min_income'][i] = 0\n",
        "      else:\n",
        "        self.user['max_income'][i] = 110     # 100이상은 모두 포함\n",
        "        self.user['min_income'][i] = 0\n",
        "\n",
        "\n",
        "  def data_creating(self):\n",
        "    train = pd.DataFrame()\n",
        "    user2 = self.user.sample(frac=1)[:3000]\n",
        "    user2['label'] = 0\n",
        "    for i in tqdm(range(0, 3000)):\n",
        "      a = pd.DataFrame([user2.iloc[i]]*1000)\n",
        "      a['정책ID'] = self.data['정책ID'].values\n",
        "      c = pd.merge(a,self.data,on='정책ID')\n",
        "      # labeling_one(c)\n",
        "      train = pd.concat([train, c], axis = 0)\n",
        "    return train\n",
        "  "
      ],
      "metadata": {
        "id": "aye3iVwwr4h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pandas.core.base import NoNewAttributesMixin\n",
        "def labeling_one(df):\n",
        "  \"\"\"\n",
        "  preprocess_label 클래스에서 사용할 조건 비교에 따른 라벨부여 함수\n",
        "  \"\"\"\n",
        "  df['label'] = None\n",
        "  df = df.reset_index()\n",
        "  for i in tqdm(range(len(df))):\n",
        "    # MB15\n",
        "    s = 0\n",
        "    if (df['기업금융지원_x'][i]== 1 and df['기업금융지원_y'][i] == 1) \\\n",
        "    or (df['교육지원(만8~19세)'][i] == 1 and df['교육지원(8~19세)'][i] == 1) \\\n",
        "    or (df['보육지원(만0~7세)'][i] == 1 and df['보육지원(0~7세)'][i] == 1) \\\n",
        "    or (df['취업 지원_x'][i] ==1 and df['취업 지원_y'][i]==1)\\\n",
        "    or (df['창업 지원_x'][i] == 1 and df['창업 지원_y'][i] == 1) \\\n",
        "    or (df['개인금융지원_x'][i] == 1 and df['개인금융지원_y'][i] == 1) \\\n",
        "    or (df['문화생활 지원_x'][i] == 1 and df['문화생활 지원_y'][i] == 1) \\\n",
        "    or (df['성인교육지원_x'][i] == 1 and df['성인교육지원_y'][i] == 1) \\\n",
        "    or (df['의료 지원_x'][i] == 1 and df['의료 지원_y'][i] == 1) \\\n",
        "    or (df['의료 지원_x'][i] == 1 and df['의료 지원_y'][i] == 1) \\\n",
        "    or (df['주택-부동산 지원_x'][i] == 1 and df['주택-부동산 지원_y'][i] == 1)\\\n",
        "    or df['관심정책없음'][i] == 1:\n",
        "      s+=1\n",
        "    # # 중위소득  -> 중위소득 관련 관계 정의를 제외하고 진행,  조건 설정 시 실제 추천 성능 개선될 것으로 예상.\n",
        "    # if ((df['max_income_x'][i] =< df['max_income_y']) \\ \n",
        "    # and (df['min_income_x'][i] => df['max_income_y'])) \\\n",
        "    # s+=1\n",
        "    #성별\n",
        "    if df['성별_x'][i] == df['성별_y'][i] or df['성별_y'][i] =='무관':\n",
        "      s += 1\n",
        "    # 결혼\n",
        "    if df['결혼_x'][i] == df['결혼_y'][i] or df['결혼_y'][i] == '무관':\n",
        "      s += 1\n",
        "    # 직장\n",
        "    if df['직장_x'][i] in df['직장_y'][i] or df['직장_y'][i] == '무관':\n",
        "      s += 1\n",
        "    # 학력\n",
        "    if df['학력_x'][i] in df['학력_y'][i] or df['학력_y'][i] == '무관':\n",
        "      s += 1\n",
        "\n",
        "    if df['국가유공자_x'][i] == df['국가유공자_y'][i] \\\n",
        "    and df['다자녀가정_x'][i] == df['다자녀가정_y'][i] \\\n",
        "    and df['한부모가정/조손가정_x'][i] == df['한부모가정/조손가정_y'][i] \\\n",
        "    and df['다문화가족_x'][i] == df['다문화가족_y'][i]  \\\n",
        "    and df['질병/부상/질환자_x'][i] == df['질병/부상/질환자_y'][i]  \\\n",
        "    and df['장애인_x'][i] == df['장애인_y'][i]  \\\n",
        "    and df[' 농축수산인'][i] == df['농축수산인'][i]  \\\n",
        "    and df['북한이탈주민_x'][i] == df['북한이탈주민_y'][i]  \\\n",
        "    and df['해당사항없음_x'][i] == df['해당사항없음_y'][i]:\n",
        "      s += 1\n",
        "    if s >= 5:\n",
        "      df['label'][i] = 1\n",
        "    else:\n",
        "      df['label'][i] = 0\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "YEMS5mauwL0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클러스터링 진행위한 정책 데이터셋 전처리\n",
        "feat = policy_clustering(data1, idx_lst)\n",
        "feat.preprocessing_feature()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6149ce7-1505-40f2-bcce-84a2007ffacd",
        "id": "9p6zzJmhZdni"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_n 개수 498\n",
            "MB_15 feature 해체 진행 \n",
            "1/5 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39340/39340 [00:31<00:00, 1268.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "중위소득 feature 변경 진행 \n",
            "2/5 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39340/39340 [00:34<00:00, 1141.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "대상특성 feature 해체 진행 \n",
            "3/5 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39340/39340 [00:25<00:00, 1527.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "직장 feature 해체 진행 \n",
            "4/5 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39340/39340 [00:17<00:00, 2208.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "지원유형 feature 해체 진행 \n",
            "5/5 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39340/39340 [00:27<00:00, 1422.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정책 데이터셋 클러스터링 진행\n",
        "feat.clustering_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5db493c-2a55-4ff7-a652-a61a0b449fb4",
        "id": "HjGwF3-tZdni"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클러스터링 진행\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 클러스터링 후 각 군집별 100개씩 sample 인덱스 추출\n",
        "data_lst = feat.clustered_idx()"
      ],
      "metadata": {
        "id": "k48NZHC8Zdnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 유저 + 정책 데이터셋 라벨 설정 인스턴스 생성\n",
        "lab = preprocessing_label(user1, data1, idx_lst, data_lst)\n",
        "lab.user_preprocessing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757417d3-f754-4bb3-e6eb-3ba1b9cb70ae",
        "id": "qg85y9uFZXDK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_n 개수 498\n",
            "정책 데이터셋 중위소득 feature 변경 진행 \n",
            "1/3 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1857.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정책 데이터셋 대상특성 feature 해체 진행 \n",
            "2/3 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1900.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정책 데이터셋 MB_15 feature 해체 진행 \n",
            "3/3 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1087.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유저 데이터셋 대상특성 feature 해체 진행 \n",
            "1/3 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14077/14077 [00:05<00:00, 2559.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유저 데이터셋 중위소득 feature 변경 진행 \n",
            "2/3 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14077/14077 [00:09<00:00, 1453.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유저 데이터셋 MB_15 feature 해체 진행 \n",
            "3/3 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14077/14077 [00:13<00:00, 1042.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유저 + 정책 데이터셋 merge\n",
        "last_data = lab.data_creating()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72dffe75-0192-4db3-b639-8af7b5ab5786",
        "id": "i1WZdDHSZXDK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [17:34<00:00,  2.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = labeled_data.copy()"
      ],
      "metadata": {
        "id": "NGHQfsmQm350"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 유저, 정책 조건에 따른 라벨 생성\n",
        "l = labeling_one(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_1W7HaqX_34",
        "outputId": "fa3079fd-c8f0-4c3d-a525-252903dffe4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000000/3000000 [7:25:01<00:00, 112.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# with open('0214.pkl' , 'wb') as f:\n",
        "#   pickle.dump(l, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "nHXaZiY5SbUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
